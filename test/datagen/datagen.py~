# A program for generating example data for "pygrametl: A Powerful Programming 
# Framework for Extract--Transform--Load Programmers"

#  
#  Copyright (c) 2009 Christian Thomsen (chr@cs.aau.dk)
#  
#  This file is free software: you may copy, redistribute and/or modify it  
#  under the terms of the GNU General Public License version 2 
#  as published by the Free Software Foundation.
#  
#  This file is distributed in the hope that it will be useful, but  
#  WITHOUT ANY WARRANTY; without even the implied warranty of  
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU  
#  General Public License for more details.  
#  
#  You should have received a copy of the GNU General Public License  
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.  
#  

import random, sys, os, getopt
from sets import Set





def get_map_num():    
    try:
        opts, args = getopt.getopt(sys.argv[1:], "h", ["help"])
    except getopt.error, msg:
        print msg
        print "for help use --help"
        sys.exit(2)

    for o, a in opts:
        if o in ("-h", "--help"):
            print __doc__
            sys.exit(0)
    return (int(args[0]), int(args[1]))



try:
    from params import toplevels
except ImportError:
    toplevels = 20

try:
    from params import domains
except ImportError:
    domains = 40

try:
    from params import pages
except ImportError:
    pages = 100

try:
    from params import months
except ImportError:
    months = 4000

try:
    from params import changeprob
except ImportError:
    changeprob = 70

try:
    from params import startyear
except ImportError:
    startyear = 1900

try:
    from params import tests
except ImportError:
    tests = 5



def generateurls():
    toplevellist = ["tl%02d" % (i,) for i in range(toplevels)]
    domainlist = ["domain%03d" % (i,) for i in range(domains)] # in each toplevel
    pagelist = ["page%03d.html" % (i,) for i in range(pages)]# in each domain

    for t in toplevellist:
        for d in domainlist:
            for p in pagelist:
                yield "http://www.%s.%s/%s" % (d, t, p)

def generate_pageinfo(outfile, nrows=sys.maxint):
    servers = ['PowerServer/1.0', 'PowerServer/2.0', 'SuperServer/3.0']
    cache = {}
    rnd = random.Random()
    rnd.seed(1) # We want to be able to recreate results

    i = 0
    year = startyear
    totalrows = 0

    for month in range(1, months + 1):
        urls = generateurls()
        if month > 1 and month % 12 == 1: # It is January in a new year
            year += 1  
        downloaddate = "%d-%02d-01" % (year,  month % 12 == 0 and 12 or month % 12)
        for url in urls:
            i += 1
            localfile = "%08d.tmp" % (i,)
            # With probability 100 - changeprob, the page wasn't changed
            tmp = rnd.randint(1,100)
            if tmp <= 100 - changeprob and url in cache:
                line = cache.get(url)
                line[0] = localfile
                line[4] = downloaddate
                if totalrows<nrows:
                    writeline(outfile, line)
                    totalrows = totalrows + 1
                    continue
                else:
                    print 'Generate %d pages' % totalrows
                    return totalrows
            # Else simulate some changes...

            # A given domain is always using the same server in this example.
            # We extract the number in the domain and use that to determine the
            # server.
            tmp = int(url.split(".tl")[0].split("domain")[1])
            server = servers[tmp % len(servers)]
            size = rnd.randint(1000, 9000)

            tmp = rnd.randint(2,28)
            if month % 12 == 1:
                lastmoddate = "%d-12-%02d" % (year - 1, tmp)
            elif month % 12 == 0:
                lastmoddate = "%d-11-%02d" % (year, tmp)
            else:
                lastmoddate = "%d-%02d-%02d" % (year, month % 12 - 1, tmp)
            line = [localfile, url, server, size, downloaddate, lastmoddate]
            cache[url] = line
            if totalrows<nrows:
                writeline(outfile, line)
                totalrows = totalrows + 1
            else:
                print 'Generate %d pages' % totalrows
                return totalrows
    print 'Generate %d pages' % totalrows
    return totalrows



def generate_tester(outfile, nrows=sys.maxint):
    testlist = ['Test%03d' % (i,) for i in range(nrows)]
    for test in testlist:
        line = (test,)
        writeline(outfile, line)
    return nrows

def generate_testresults(pageinfo, npage, ntest, outfile, nrows=sys.maxint):
    rnd = random.Random()
    for i in range(nrows):
        test = 'Test%03d' %  rnd.randint(0, ntest)
        length = 95*rnd.randint(1, npage-1)
        pageinfo.seek(length)
        pageline = pageinfo.readline()
        #print pageline
        if pageline==None or pageline=='':
            print length
            print pageline
            return
        logfields = pageline.split('\t')

        line = (logfields[0], logfields[1], logfields[5].rstrip('\n'), logfields[4], test, rnd.randint(10, 99))
        writeline(outfile, line)


def writeline(outfile, fields):
    outfile.write("\t".join([str(f) for f in fields]))
    outfile.write("\n")




def main():
    pagesize, resultsize = get_map_num()
    #filesize = 1000*1000*1000*gb

    #pattern = "/data1/cloudetldata/%s" 
    fpattern = "%s" 

    pageinfo = open(fpattern%"PageInfo%d.csv"%pagesize, 'w', 16384)
    tester = open(fpattern%'Tester.csv', 'w', 16384)
    testresults = open(fpattern%"TestResults%d.csv"%resultsize, 'w', 16384)    

    try:
        #writeline(pageinfo, ['localfile', 'url', 'serverversion', 'size', 'downloaddate', 'lastmoddate'])
        #writeline(tester, ['test', ])

        #writeline(testresults, ['localfile', 'url', 'lastmoddate', 'downloaddate', 'test', 'errors'])
        npage = pagesize*1024*1024*1024/95  #11302545 
        ntest = 200
        ntestresult = resultsize*1024*1024*1024/85
        npage=generate_pageinfo(pageinfo, npage)
        ntest=generate_tester(tester, ntest)

        pageinfo.close()
        pageinfo = open(fpattern%"PageInfo%d.csv"%pagesize)
        generate_testresults(pageinfo, npage, ntest, testresults, ntestresult)
    finally:
        pageinfo.close()
        tester.close()
        testresults.close()



if __name__ == "__main__":
    main()
